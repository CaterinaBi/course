<!-- DISABLE-FRONTMATTER-SECTIONS -->

# Quiz di fine capitolo

In questo capitolo abbiamo parlato di molti argomenti! Non preoccuparti se non hai capito tutto nel dettaglio: i prossimi capitoli ti aiuteranno a capire come molte di queste cose funzionano dietro le quinte.

Prima di procedere, per√≤, verifichiamo cos'hai imparato in questo capitolo!


### 1. Esplora l'Hub e cerca il checkpoint `roberta-large-mnli`. Quale compito svolge?


<Question
	choices={[
		{
			text: "Riassunto testuale",
			explain: "Rivisita il link e prova di nuovo: <a href=\"https://huggingface.co/roberta-large-mnli\">roberta-large-mnli page</a>."
		},
		{
			text: "Classificazione testuale",
			explain: "Pi√π precisamente, determina se due frasi sono connesse logicamente su tre livelli associati alle etichette 'contradiction', 'neutral' e 'entailment'. Questo compito viene detto anche <em>natural language inference</em>.",
			correct: true
		},
		{
			text: "Generazione testuale",
			explain: "Rivisita il link e prova di nuovo: <a href=\"https://huggingface.co/roberta-large-mnli\">roberta-large-mnli page</a>."
		}
	]}
/>

### 2. Cosa restituisce il codice seguente?

```py
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

<Question
	choices={[
		{
			text: "Restituisce un punteggio associato alla frase, con etichette del tipo \"positive\" o \"negative\".",
			explain: "Sbagliato! Se cos√¨ fosse, si tratterebbe di una pipeline di tipo <code>sentiment-analysis</code>."
		},
		{
			text: "Genera e restituisce testo che completa la frase di partenza.",
			explain: "Sbagliato! Se cos√¨ fosse, si tratterebbe di una pipeline di tipo <code>text-generation</code>.",
		},
		{
			text: "Restituisce i termini che rappresentano persone, organizzazioni o luoghi.",
			explain: "Inoltre, grazie a <code>grouped_entities=True</code>, la pipeline √® in grado di raggruppare le parole che appartengono alla stessa entit√†, come \"Hugging Face\".",
			correct: true
		}
	]}
/>

### 3. Cosa dovrebbe rimpiazzare "..." in questo estratto di codice?

```py
from transformers import pipeline

filler = pipeline("fill-mask", model="bert-base-cased")
result = filler("...")
```

<Question
	choices={[
		{
			text: "Questo &#60;mask> aspetta te.",
			explain: "Sbagliato. Controlla la card del modello <code>bert-base-cased</code> e cerca di capire il tuo errore."
		},
		{
			text: "Questo [MASK] aspetta te.",
			explain: "Corretto! Il mask token utilizzato dal modello √® [MASK].",
			correct: true
		},
		{
			text: "Questo signore aspetta te.",
			explain: "Sbagliato. Questa pipeline completa parole nascoste, quindi necessita di un mask token nell'input."
		}
	]}
/>

### 4. Perch√© questo codice non funziona?

```py
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
result = classifier("This is a course about the Transformers library")
```

<Question
	choices={[
		{
			text: "Questa pipeline richiede che le etichette siano fornite per poter classificare il testo.",
			explain: "Esatto! Per essere corretto, il codice deve includere <code>candidate_labels=[...]</code>.",
			correct: true
		},
		{
			text: "Questa pipeline richiede diverse frasi, non solo una.",
			explain: "Sbagliato, anche se quando usata correttamente, questa pipeline pu√≤ tranquillamente processare una lista di frasi (come tutte le altre pipeline)."
		},
		{
			text: "COme al solito, la libreria Transformer di ü§ó non funziona.",
			explain: "Ci rifiutiamo di commentare la tua risposta!"
		}
		{
			text: "Questa pipeline richiede un input pi√π lungo. Quello fornito √® troppo corto.",
			explain: "Sbagliato. Sappi che per processare testi molto lunghi, questa pipeline li deve troncare."
		}
	]}
/>

### 5. Cosa significa "transfer learning"?

<Question
	choices={[
		{
			text: "Trasferire la conoscenza di un modello pre-addestrato a un nuovo modello, addestrando quest'ultimo sulla stessa banca dati.",
			explain: "No, in quel caso avremmo a che fare con due versioni dello stesso modello."
		},
		{
			text: "Trasferire la conoscenza di un modello pre-addestrato a un nuovo modello addestrando il secondo con i pesi del primo.",
			explain: "Corretto. Quando il secondo modello viene addestrato ad un nuovo compito, *trasferisce* la conoscenza del primo modello.",
			correct: true
		},
		{
			text: "Trasferire la conoscenza di un modello pre-addestrato a un nuovo modello costruendo il secondo con la stessa architettura del primo.",
			explain: "L'architettuta √® semplicemente il modo in cui il modello √® costruito. In questo caso, la conoscenza non √® n√© condivisa n√© trasmessa."
		}
	]}
/>

### 6. Vero o falso? Solitamente un modello linguistico non richiede etichette in fase di pre-addestramento.


<Question
	choices={[
		{
			text: "Vero",
			explain: "Solitamente, il pre-addestramento √® <em>self-supervised</em>, il che significa che le etichette sono create direttamente a partire dall'input (come quando una pipeline predice la parola seguente o indovina parole nascoste).",
			correct: true
		},
		{
			text: "Falso",
			explain: "La risposta non √® corretta."
		}
	]}
/>

### 7. Seleziona la frase che meglio descrive i termini "modello," "architettura," e "pesi."

<Question
	choices={[
		{
			text: "If a model is a building, its architecture is the blueprint and the weights are the people living inside.",
			explain: "Following this metaphor, the weights would be the bricks and other materials used to construct the building."
		},
		{
			text: "An architecture is a map to build a model and its weights are the cities represented on the map.",
			explain: "The problem with this metaphor is that a map usually represents one existing reality (there is only one city in France named Paris). For a given architecture, multiple weights are possible."
		},
		{
			text: "An architecture is a succession of mathematical functions to build a model and its weights are those functions parameters.",
			explain: "The same set of mathematical functions (architecture) can be used to build different models by using different parameters (weights).",
			correct: true
		}
	]}
/>


### 8. Quale dei seguenti modelli utilizzeresti per completare dei prompt con testo generato?

<Question
	choices={[
		{
			text: "An encoder model",
			explain: "An encoder model generates a representation of the whole sentence that is better suited for tasks like classification."
		},
		{
			text: "A decoder model",
			explain: "Decoder models are perfectly suited for text generation from a prompt.",
			correct: true
		},
		{
			text: "A sequence-to-sequence model",
			explain: "Sequence-to-sequence models are better suited for tasks where you want to generate sentences in relation to the input sentences, not a given prompt."
		}
	]}
/>

### 9. Quale dei seguenti modelli utilizzeresti per riassumere testi?

<Question
	choices={[
		{
			text: "An encoder model",
			explain: "An encoder model generates a representation of the whole sentence that is better suited for tasks like classification."
		},
		{
			text: "A decoder model",
			explain: "Decoder models are good for generating output text (like summaries), but they don't have the ability to exploit a context like the whole text to summarize."
		},
		{
			text: "A sequence-to-sequence model",
			explain: "Sequence-to-sequence models are perfectly suited for a summarization task.",
			correct: true
		}
	]}
/>

### 10. Quale dei seguenti modelli utilizzeresti per classificare input testuali sulla base di determinate etichette?

<Question
	choices={[
		{
			text: "An encoder model",
			explain: "An encoder model generates a representation of the whole sentence which is perfectly suited for a task like classification.",
			correct: true
		},
		{
			text: "A decoder model",
			explain: "Decoder models are good for generating output texts, not extracting a label out of a sentence."
		},
		{
			text: "A sequence-to-sequence model",
			explain: "Sequence-to-sequence models are better suited for tasks where you want to generate text based on an input sentence, not a label.",
		}
	]}
/>

### 11. Qual √® la possibile origine di un bias osservato in un modello?

<Question
	choices={[
		{
			text: "The model is a fine-tuned version of a pretrained model and it picked up its bias from it.",
			explain: "When applying Transfer Learning, the bias in the pretrained model used perspires in the fine-tuned model.",
			correct: true
		},
		{
			text: "The data the model was trained on is biased.",
			explain: "This is the most obvious source of bias, but not the only one.",
			correct: true
		},
		{
			text: "The metric the model was optimizing for is biased.",
			explain: "A less obvious source of bias is the way the model is trained. Your model will blindly optimize for whatever metric you chose, without any second thoughts.",
			correct: true
		}
	]}
/>
