# Riassunto

In questo capitolo, hai scoperto come approcciare diversi compiti di NLP utilizzando la funzione di alto livello `pipeline()` degli ü§ó Transformer. Abbiamo anche visto come cercare e utilizzare i modelli dell'Hub, nonch√© come usare l'Inference API per testare i modelli direttamente nel tuo browser.

We discussed how Transformer models work at a high level, and talked about the importance of transfer learning and fine-tuning. A key aspect is that you can use the full architecture or only the encoder or decoder, depending on what kind of task you aim to solve. The following table summarizes this:

| Modello         | Esempi                                     | Compiti                                                                          |
|-----------------|--------------------------------------------|----------------------------------------------------------------------------------|
| Encoder         | ALBERT, BERT, DistilBERT, ELECTRA, RoBERTa | Classificazione frasale, riconoscimento delle entit√† nominate, estrazione di     |
|                 |                                            | risposte a domande                                                               |
| Decoder         | CTRL, GPT, GPT-2, Transformer XL           | Generazione di testi                                                             |
| Encoder-decoder | BART, T5, Marian, mBART                    | Riassunti, traduzione, generazione di risposte a domande                         |
